{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c9d657-e97c-45b9-b132-4f9a1e817c09",
   "metadata": {},
   "source": [
    "# Der Höhepunkt: SQL, Spark-Tables, Reporting ...\n",
    "\n",
    "* SQL Abfragen auf Dataframes anwenden\n",
    "* Mit Spark Datenbanken & Tabellen arbeiten\n",
    "* User-Defined Functions benutzen\n",
    "* Datenmegen joinen\n",
    "* Testdaten erzeugen, welche zwei Geschäftsprozesse aus der Versicherungswelt abbilden\n",
    "* Die ersten (und wesentlichsten) Schritte für ein sinnvolles Monitoring dieser Prozesse gehen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb03304-9de0-40e1-b3ac-843e16c0ef9c",
   "metadata": {},
   "source": [
    "## Wie immer eine Spark-Application registieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b904ba-baea-447b-86a5-0640e887ee74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/lib/python3.10/dist-packages/pyspark'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28fd1b01-e8cb-4f68-b89c-4ecce0c5d0fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/10 09:18:24 WARN Utils: Your hostname, keen-northcutt resolves to a loopback address: 127.0.1.1; using 116.203.107.225 instead (on interface eth0)\n",
      "23/09/10 09:18:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/10 09:18:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/09/10 09:18:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/09/10 09:18:27 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/09/10 09:18:27 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "23/09/10 09:18:27 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://keen-northcutt.bin-ich-tot.de:4044\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sql</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8a3cb20370>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"sql\")\n",
    "        .config(\"spark.dynamicAllocation.enabled\",False)\n",
    "        .config(\"spark.sql.adaptive.enabled\",False)\n",
    "        .master(\"local[4]\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb782484-df8a-4887-85b3-ff1a071b3f85",
   "metadata": {},
   "source": [
    "## Nun Testdaten erzeugen\n",
    "Hierzu haben wir ein Beispiel aus der Versicherungswelt vorbereiten. Vielleicht ist es dem in der Signal sogar ein bisschen ähnlich ;-)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fe6873-4e84-43c4-9ebe-80ada0d84831",
   "metadata": {},
   "source": [
    "![](architecture-level-01.dio.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e73784-9780-4b5c-a47b-30e6cdfdf20b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import generate_test_data\n",
    "generate_test_data.main(1000) # führe das nur _einmal_ aus!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9467f314-57c1-498e-9a7f-e91e5350e433",
   "metadata": {
    "tags": []
   },
   "source": [
    "Wir sehen nun auf im Dateibrowser eine Liste von Dateien, die überwiegend fachliche Events enthalten, die zwei Geschäftsprozesse abbilden:\n",
    "\n",
    "### Ein Kunden bekommt einen neuen Vertrag\n",
    "\n",
    "Die Systeme, die die Events schreiben liegen in der Verantwortung verschiedener Teams:\n",
    "\n",
    "#### Team Antrag\n",
    " * **Antrag Erzeugt:** Der Kunde benutzt über das Web ein System, um einen Antrag auf einen Versicherungsvertrag zu stellen. Dieses System validert schon ein wenig, versucht einen schon bestehenden Kunden im Partner-Systeme zu finden und veröffentlicht im Anschluss dieses Business-Event.\n",
    " * **AB-Test:** Das Team Antrag ist stehst bemüht die User-Experience zu optimieren. So möchte es zum Beispiel die Durchlaufzeit auf seinem eigenen System zu verkürzen. Dazu variert es z.B. die Farbe eines Knopfes. Wenn bei einem Antrag die Standardfarbe des Knopfes abweicht, veröffentlicht es dieses technische Event\n",
    " * **Kunde hat Angebot aktzeptiert:** Nachdem das Vertragssystem sein grünes Licht gegeben hat, wurde der Vertrag vom Kunden auch akzeptiert.\n",
    " * **Kunde hat Angebot abgelehnt:** Wie vorhergehendes Event nur der Kunde will das Angebot nicht annehmen.\n",
    " \n",
    "#### Team Vertrag\n",
    " * **Antrag abgelehnt**: Ein Antrag kann vom Vertragssystem abgelehnt werden. Dieses fragt z.B. noch bei Fraud an und validert auch sonst den Antrag viel \"besser\" als es das Antragssystem könnte.\n",
    " * **Kunde angelegt**: (eigentlich müsste ein anderes System dieses Event schreiben, aber in unserem Beispiel soll das mal OK sein) Wenn in einem Antrag nicht schon eine Referenz auf einen Kunden vorhanden ist, dann legt das Vertragssystem einen Kunden an und informiert Gott und die Welt hierüber, indem es dieses Event veröffentlicht.\n",
    " * **Vertrag angeboten**: Wenn ein Vertragsantrag aus Sicht des Vertragssystems gut aussieht, dann gibt es den Vertrag frei zur Annahme durch den Kunden. \n",
    " * **Vertrag policiert**: Wenn der Kunde ein Vertragsangebot akzeptiert hat, policieren wir den Vertrag. Nun ist der Kunde versichert. Jetzt können bedenkenlos Schadensfälle eintreten.\n",
    " \n",
    "#### Team Schaden\n",
    " * **Schaden reguliert**: wenn ein Schadensfall geprüft wurde und alles passt, dann überweisen wir Geld\n",
    "\n",
    "#### Übrigens\n",
    "**kunden.csv** ist nur ein Container mit allen Kunden ;-)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeeb418-98c1-436d-b13f-d319c4420962",
   "metadata": {},
   "source": [
    "## Erste Blicke in unsere Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bcb483-6bc7-4786-9171-f5fad2a699fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "+------------------------------------+--------------+\n",
      "|id                                  |name          |\n",
      "+------------------------------------+--------------+\n",
      "|ce4cf720-4a1a-11ee-8349-7b31dfcc7252|gorzala       |\n",
      "|d55a2ede-4a1a-11ee-8cce-b739d8c6e256|Olli          |\n",
      "|1dbdbea0-814b-46ee-88a5-a92e30231a18|Relaxed Cray  |\n",
      "|8b5d9978-c30a-4b32-85cb-8dd901c822bd|Pedantic Ellis|\n",
      "+------------------------------------+--------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kunden_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"kunden.csv\")\n",
    "kunden_df.printSchema()\n",
    "kunden_df.show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb40d3f-36c3-4e93-8b5a-0925cead5fc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "Soweit so bekannt. Wir könnten jetzt auf die Daten zugreifen in dem wir wie in den vorhergegangen Kapiteln filter anwenden, Null-Werte entfernen usw.\n",
    "Wir möchten aber ab sofort ganz normal mit SQL auf unsere Daten zugreifen. Dazu müssen wir zu einem Dataframe in Spark einen _View_ anlegen. Diese Views werden dann ganz normal wie Datenbanktabellen in SQL-Datenbanken behandelt (read-only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5542e6b6-4131-4e40-8cc0-cc59eb30c4e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kunden_df.createOrReplaceTempView(\"kunden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd663dc-7343-45ee-a11d-d4c239282abd",
   "metadata": {},
   "source": [
    "**Beachte:** die Funktion gibt nichts zurück. In der Spark-Application ist jetzt eine eine Tabelle unter dem Namen \"kunden\" verfügbar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29602ac9-7eec-46ca-8a78-d388b378bf57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, name: string]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM kunden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f3882-06ed-48bd-9a47-f15395c21d2c",
   "metadata": {},
   "source": [
    "Wir sehen das wir ein Dataframe zurückbekommen. Auf diesem können wir dann wieder die bekannten Operationen ausführen. Beachte, ob Du die Dateframe-API oder die SQL-API nutzt, hat in der Regel **keinen** Impact auf die Performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39e8898-cb49-4cbc-a10d-6dd4515e8ea8",
   "metadata": {},
   "source": [
    "**Übung** setzte hier mal ein paar SQLs gegen diese Tabelle ab. Filter nach bestimmten Namen... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3df4036e-3276-4df3-b507-8ac26ae1bf94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                  id|                name|\n",
      "+--------------------+--------------------+\n",
      "|ce4cf720-4a1a-11e...|             gorzala|\n",
      "|d55a2ede-4a1a-11e...|                Olli|\n",
      "|1dbdbea0-814b-46e...|        Relaxed Cray|\n",
      "|8b5d9978-c30a-4b3...|      Pedantic Ellis|\n",
      "|0232746d-2025-4dc...|  Mystifying Solomon|\n",
      "|331c4f94-82ad-443...|          Elastic Wu|\n",
      "|f783150d-95d6-425...|       Hardcore Cori|\n",
      "|89b2f281-5743-42b...|   Inspiring Solomon|\n",
      "|12c4de06-eb24-4b4...|Competent Montalcini|\n",
      "|129d91bf-35b6-44b...|        Jovial Rubin|\n",
      "|bc5967d0-2077-4d6...|            Zen Pike|\n",
      "|4b9d040f-8432-429...|   Objective Goodall|\n",
      "|14f2a015-c9e9-4bb...|   Distracted Bouman|\n",
      "|23ac28d5-0247-4e9...|   Mystifying Agnesi|\n",
      "|05a0c2f2-5701-432...|   Nostalgic Pasteur|\n",
      "|cab57827-f0bf-497...|    Awesome Poincare|\n",
      "|945cec5c-a952-4a1...|      Sleepy Hermann|\n",
      "|da324d84-5b3d-400...|  Epic Proskuriakova|\n",
      "|51249084-0897-4b6...|      Charming Gauss|\n",
      "|d4a3bf2f-66aa-485...|      Unruffled Benz|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM kunden').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e879e92f-a73a-431f-a7ba-71ac0461eba6",
   "metadata": {},
   "source": [
    "## Alle Testdaten importieren\n",
    "und views anlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "561abcf9-a58a-42e1-b2e3-857e7a7400f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AB-test\n",
    "ab_test_schema = \"AntragsId STRING\"\n",
    "ab_test_df = spark.read.option(\"header\", True).schema(ab_test_schema).csv(\"ab_test.csv\")\n",
    "ab_test_df.createOrReplaceTempView(\"ab_test\")\n",
    "\n",
    "# Antrag Abgelehnt\n",
    "antrag_abgelehnt_schema = \"AntragsId STRING, KundenId STRING, TimeStamp TIMESTAMP, Grund STRING\"\n",
    "antrag_abgelehnt_df = spark.read.option(\"header\", True).schema(antrag_abgelehnt_schema).csv(\"antrag_abgelehnt.csv\")\n",
    "antrag_abgelehnt_df.createOrReplaceTempView(\"antrag_abgelehnt\")\n",
    "\n",
    "# Antrag Erzeugt\n",
    "antrag_erzeugt_schema = \"AntragsId STRING, StartZeit TIMESTAMP, EndZeit TIMESTAMP, KundenId STRING\"\n",
    "antrag_erzeugt_df = spark.read.option(\"header\", True).schema(antrag_erzeugt_schema).csv(\"antrag_erzeugt.csv\")\n",
    "antrag_erzeugt_df.createOrReplaceTempView(\"antrag_erzeugt\")\n",
    "\n",
    "# Kunde Angelegt\n",
    "kunde_angelegt_schema = \"KundenId STRING, TimeStamp TIMESTAMP\"\n",
    "kunde_angelegt_df = spark.read.option(\"header\", True).schema(kunde_angelegt_schema).csv(\"kunde_angelegt.csv\")\n",
    "kunde_angelegt_df.createOrReplaceTempView(\"kunde_angelegt\")\n",
    "\n",
    "# Kunde hat Angebot Abgelehnt\n",
    "kunde_hat_angebot_abgelehnt_schema = \"VertragsId STRING, AntragsId STRING, Grund STRING, TimeStamp TIMESTAMP\"\n",
    "kunde_hat_angebot_abgelehnt_df = spark.read.option(\"header\", True).schema(kunde_hat_angebot_abgelehnt_schema).csv(\"kunde_hat_angebot_abgelehnt.csv\")\n",
    "kunde_hat_angebot_abgelehnt_df .createOrReplaceTempView(\"kunde_hat_angebot_abgelehnt\")\n",
    "\n",
    "# Kunde hat Angebot Akzeptiert\n",
    "kunde_hat_angebot_akzeptiert_schema = \"VertragsId STRING, AntragsId STRING, KundenId STRING, TimeStamp TIMESTAMP\"\n",
    "kunde_hat_angebot_akzeptiert_df = spark.read.option(\"header\", True).schema(kunde_hat_angebot_akzeptiert_schema).csv(\"kunde_hat_angebot_akzeptiert.csv\")\n",
    "kunde_hat_angebot_akzeptiert_df.createOrReplaceTempView(\"kunde_hat_angebot_akzeptiert\")\n",
    "\n",
    "# Schaden Gemeldet\n",
    "schaden_gemeldet_schema = \"VertragsId STRING, SchadensId STRING, Schadenshoehe INT, TimeStamp TIMESTAMP\"\n",
    "schaden_gemeldet_df = spark.read.option(\"header\", True).schema(schaden_gemeldet_schema).csv(\"schaden_gemeldet.csv\")\n",
    "schaden_gemeldet_df.createOrReplaceTempView(\"schaden_gemeldet\")\n",
    "\n",
    "# Schaden Reguliert\n",
    "schaden_reguliert_schema = \"SchadensId STRING, TimeStamp TIMESTAMP\"\n",
    "schaden_reguliert_df = spark.read.option(\"header\", True).schema(schaden_reguliert_schema).csv(\"schaden_reguliert.csv\")\n",
    "schaden_reguliert_df.createOrReplaceTempView(\"schaden_reguliert\")\n",
    "\n",
    "# Vertrag Angeboten\n",
    "vertrag_angeboten_schema = \"VertragsId STRING, AntragsId STRING, KundenId STRING, TimeStamp TIMESTAMP\"\n",
    "vertrag_angeboten_df = spark.read.option(\"header\", True).schema(vertrag_angeboten_schema).csv(\"vertrag_angeboten.csv\")\n",
    "vertrag_angeboten_df.createOrReplaceTempView(\"vertrag_angeboten\")\n",
    "\n",
    "# Vertrag Policiert\n",
    "vertrag_policiert_schema = \"VertragsId STRING, TimeStamp TIMESTAMP\"\n",
    "vertrag_policiert_df = spark.read.option(\"header\", True).schema(vertrag_policiert_schema).csv(\"vertrag_policiert.csv\")\n",
    "vertrag_policiert_df.createOrReplaceTempView(\"vertrag_policiert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "443150a9-ae9f-43a0-b299-f7f49f157123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------------------+-----------+\n",
      "|namespace|tableName                   |isTemporary|\n",
      "+---------+----------------------------+-----------+\n",
      "|default  |mytesttable2                |false      |\n",
      "|         |ab_test                     |true       |\n",
      "|         |antrag_abgelehnt            |true       |\n",
      "|         |antrag_erzeugt              |true       |\n",
      "|         |kunde_angelegt              |true       |\n",
      "|         |kunde_hat_angebot_abgelehnt |true       |\n",
      "|         |kunde_hat_angebot_akzeptiert|true       |\n",
      "|         |kunden                      |true       |\n",
      "|         |schaden_gemeldet            |true       |\n",
      "|         |schaden_reguliert           |true       |\n",
      "|         |vertrag_angeboten           |true       |\n",
      "|         |vertrag_policiert           |true       |\n",
      "+---------+----------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# alles da?\n",
    "spark.sql(\"SHOW TABLES\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc50f92f-8c67-4938-a6d5-768ba374cf36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-------+\n",
      "|     col_name|data_type|comment|\n",
      "+-------------+---------+-------+\n",
      "|    VertagsId|   string|   null|\n",
      "|   SchadensId|   string|   null|\n",
      "|Schadenshoehe|      int|   null|\n",
      "|    TimeStamp|timestamp|   null|\n",
      "+-------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stichprobe bzgl. der Datentypen?\n",
    "spark.sql(\"DESCRIBE TABLE EXTENDED schaden_gemeldet\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3661e5a-a183-41b1-92f1-50fc718b3618",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ein erstes Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e5d6f0-0e58-40f4-9780-6d9aafee0ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    1000|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     119|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Zeige alle Anträge an, bei den wir die Farbe des Knopfs verändert haben\n",
    "# erstmal alle Anträge\n",
    "\n",
    "spark.sql(\"SELECT count(1) FROM antrag_erzeugt\").show()\n",
    "\n",
    "# Und nun die wo wir den Knopf verändert haben\n",
    "spark.sql(\"\"\"\n",
    "     SELECT count(1)\n",
    "       FROM antrag_erzeugt\n",
    " INNER JOIN ab_test\n",
    "         ON antrag_erzeugt.AntragsId = ab_test.AntragsId\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f5d6be-2236-4e94-90b0-bc9b5199fb2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Aufgabe** Erzeuge eine Abfrage, die folgendes berechnet: Durchlaufzeit für den normalen Fall (Knopffarbe hat sich nicht geändert) und für den Fall Knopffarbe hat sich gerändert.\n",
    "\n",
    "Wenn die das zu schwer ist, fange an mit einer Abfrage für den normalen Fall und eine für den Farbewechselfall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58183d96-c895-41ea-9b36-ea8e71776a0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spark Tables\n",
    "\n",
    "Bisher haben wir gesehen, wie wir CSV Dateien laden und speichern können.\n",
    "Dabei mussten wir allerdings immer ein Schema angeben.\n",
    "Das ist auf Dauer lästig und mindestens aufwendig.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0f1a09-5220-4896-b3d0-67c5c8e489e0",
   "metadata": {},
   "source": [
    "![](spark-catalog.dio.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c5cede6-1c4a-4bb2-b6d9-913cd1d11686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- KundenId: string (nullable = true)\n",
      " |-- TimeStamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# beispiel mit dem Kunde angelegt Event\n",
    "kunde_angelegt_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "968cecf6-5b8c-4750-83e4-803566d0cb3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "kunde_angelegt_df.write.mode(\"overwrite\").saveAsTable(\"myTestTable2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "effc471a-bb43-4883-93a0-dd622203cea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kunde_angelegt_df = spark.read.table(\"myTestTable2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3235f26c-1453-47da-aff6-2c770b53d58d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- KundenId: string (nullable = true)\n",
      " |-- TimeStamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kunde_angelegt_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c52561-1dfc-4137-9025-9e1d1c74d5a9",
   "metadata": {},
   "source": [
    "wir können aber auch direkt mit SQL aus einer Table lesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aa42a73-c842-40f1-8483-a7860c02309e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[KundenId: string, TimeStamp: timestamp]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM myTestTable2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f002581-b254-4ed3-a840-03894cd696d5",
   "metadata": {},
   "source": [
    "### Typen von Catalogs\n",
    "\n",
    "\n",
    "* **In-memory Catalog** Wenn eine Spark-Sitzung ended, wird auch der Catalog aufgeräumt\n",
    "* **Persistent Catalog** Metadaten werden permanent gespeichert, Spark hat einen [Hive](https://hive.apache.org/)-basierten Catalog eingebaut.\n",
    "\n",
    "### Typen von Tables\n",
    "\n",
    "* **Managed Tables** Spark kümmert sich um den Lebenszyklus. Es werden Daten und Schemata verwaltet. Nützlich für staging Daten. Wenn eine Tabelle gelöscht wird, dann werden Daten und Schemata gelöscht.\n",
    "* **Unmanged Tables/External Tables** Das Schema wird auch hier von Spark gemanaged, aber die Daten in einer frei wählbaren location. Löschen einer Tabelle löscht hier nur das Schema. Nützlich für das Ergebniss von ETL Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd8f02ca-6964-4f02-b50b-21cd3c42096b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/04 14:42:17 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://pupil-a.bin-ich-tot.de:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sql</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f63f8a03310>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from IPython.display import *\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"SparkTablesApp\")\n",
    "        .master(\"local[4]\")\n",
    "        .config(\"spark.dynamicAllocation.enabled\", \"false\")\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"false\")\n",
    "        \n",
    "        .enableHiveSupport() # <---------------------------------\n",
    "    \n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "sc = spark.sparkContext\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cc15e8-4dcf-42e8-8c52-d92d451cb47f",
   "metadata": {},
   "source": [
    "### Nun eine Datenbank in Hive erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a6875fe-33f8-48f9-9601-51053c608936",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SHOW DATABASES\n",
    "  \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c099fd9f-19de-4189-9ac4-5d8b33f6507f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    CREATE DATABASE IF NOT EXISTS Foo\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b80f7789-bea6-4227-a7bc-ba3dd40d5fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|      foo|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SHOW DATABASES\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4648f4fb-3f85-47ab-8551-6f7cdc4c752e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kunde_angelegt_df.write.mode(\"overwrite\").saveAsTable(\"foo.bar\")\n",
    "# wurde als managed table abgespeichert, da keine externe location angegeben wurde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdacfcd3-f208-4335-9fa8-b97e5f7985c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------------------+-----------+\n",
      "|namespace|tableName                   |isTemporary|\n",
      "+---------+----------------------------+-----------+\n",
      "|default  |mytesttable2                |false      |\n",
      "|         |ab_test                     |true       |\n",
      "|         |antrag_abgelehnt            |true       |\n",
      "|         |antrag_erzeugt              |true       |\n",
      "|         |kunde_angelegt              |true       |\n",
      "|         |kunde_hat_angebot_abgelehnt |true       |\n",
      "|         |kunde_hat_angebot_akzeptiert|true       |\n",
      "|         |kunden                      |true       |\n",
      "|         |schaden_gemeldet            |true       |\n",
      "|         |schaden_reguliert           |true       |\n",
      "|         |vertrag_angeboten           |true       |\n",
      "|         |vertrag_policiert           |true       |\n",
      "+---------+----------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SHOW TABLES in default\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6729ea1-241c-4ece-b93a-05fc0fbf52de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|            KundenId|          TimeStamp|\n",
      "+--------------------+-------------------+\n",
      "|cab57827-f0bf-497...|2023-09-17 07:33:51|\n",
      "|7962496d-8b1a-468...|2023-09-01 16:48:04|\n",
      "|f75bc42b-cc5f-457...|2023-09-16 08:06:43|\n",
      "|bcd595a1-7417-48a...|2023-09-02 03:55:48|\n",
      "|631ec411-4379-4ac...|2023-09-16 11:48:36|\n",
      "|4c94784d-27c8-4c3...|2023-09-11 19:40:10|\n",
      "|e4a9b53a-6590-4d6...|2023-09-14 06:03:20|\n",
      "|18666e62-c367-410...|2023-09-17 19:06:53|\n",
      "|2b969628-a210-4df...|2023-09-07 07:07:48|\n",
      "|c05e8ec3-ce7d-43f...|2023-09-12 04:17:26|\n",
      "|2ecf7929-add0-47b...|2023-09-15 17:55:03|\n",
      "|217502fb-7070-4eb...|2023-09-08 03:47:06|\n",
      "|e21ac097-dff6-438...|2023-09-12 20:06:39|\n",
      "|44b04de1-40ff-424...|2023-09-07 16:38:51|\n",
      "|f357e4f0-9248-4fc...|2023-09-11 02:32:09|\n",
      "|f1726fb3-37aa-443...|2023-09-11 16:47:04|\n",
      "|67c689a1-151a-4fd...|2023-09-17 04:59:07|\n",
      "|5a04500d-5ad1-495...|2023-09-05 11:23:34|\n",
      "|fb363d72-6531-426...|2023-09-07 23:39:07|\n",
      "|3aa73b67-1086-42d...|2023-09-19 20:04:50|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * from foo.bar\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35d654b9-2271-4d8d-988e-d07529f63c93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- KundenId: string (nullable = true)\n",
      " |-- TimeStamp: timestamp (nullable = true)\n",
      "\n",
      "+--------------------+-------------------+\n",
      "|            KundenId|          TimeStamp|\n",
      "+--------------------+-------------------+\n",
      "|cab57827-f0bf-497...|2023-09-17 07:33:51|\n",
      "|7962496d-8b1a-468...|2023-09-01 16:48:04|\n",
      "+--------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# oder auch die Tabelle direkt in ein Dataframe lesen\n",
    "\n",
    "tmp = spark.read.table(\"foo.bar\")\n",
    "tmp.printSchema()\n",
    "tmp.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a6fa565-9e03-4567-97e4-938bb261ba2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+----------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                             |comment|\n",
      "+----------------------------+----------------------------------------------------------------------+-------+\n",
      "|KundenId                    |string                                                                |null   |\n",
      "|TimeStamp                   |timestamp                                                             |null   |\n",
      "|                            |                                                                      |       |\n",
      "|# Detailed Table Information|                                                                      |       |\n",
      "|Catalog                     |spark_catalog                                                         |       |\n",
      "|Database                    |foo                                                                   |       |\n",
      "|Table                       |bar                                                                   |       |\n",
      "|Created Time                |Mon Sep 04 14:43:12 UTC 2023                                          |       |\n",
      "|Last Access                 |UNKNOWN                                                               |       |\n",
      "|Created By                  |Spark 3.4.1                                                           |       |\n",
      "|Type                        |MANAGED                                                               |       |\n",
      "|Provider                    |parquet                                                               |       |\n",
      "|Location                    |file:/home/pupil/spark-course/course/03-SQL/spark-warehouse/foo.db/bar|       |\n",
      "+----------------------------+----------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Nun schauen wir uns mal die Details der Tabelle an\n",
    "spark.sql(\"\"\"\n",
    "    DESCRIBE TABLE EXTENDED foo.bar\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82775ae5-c77b-4ede-af98-b194fcccd001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nun eine UNMANAGED Table anlegen\n",
    "(\n",
    "    kunden_df\n",
    "        .write\n",
    "        .mode(\"overwrite\")\n",
    "        .option(\"path\", \"/home/pupil/spark-course/course/03-SQL/spark-warehouse/persistent/kunden.parquet\")\n",
    "        #.option(\"format\", \"csv\") # defaults to parquet\n",
    "        .saveAsTable(\"foo.bar\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3370f8c-7f02-4b72-ad18-eb7d1a8121e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                              |comment|\n",
      "+----------------------------+---------------------------------------------------------------------------------------+-------+\n",
      "|id                          |string                                                                                 |null   |\n",
      "|name                        |string                                                                                 |null   |\n",
      "|                            |                                                                                       |       |\n",
      "|# Detailed Table Information|                                                                                       |       |\n",
      "|Catalog                     |spark_catalog                                                                          |       |\n",
      "|Database                    |foo                                                                                    |       |\n",
      "|Table                       |bar                                                                                    |       |\n",
      "|Created Time                |Mon Sep 04 14:46:43 UTC 2023                                                           |       |\n",
      "|Last Access                 |UNKNOWN                                                                                |       |\n",
      "|Created By                  |Spark 3.4.1                                                                            |       |\n",
      "|Type                        |EXTERNAL                                                                               |       |\n",
      "|Provider                    |parquet                                                                                |       |\n",
      "|Location                    |file:///home/pupil/spark-course/course/03-SQL/spark-warehouse/persistent/kunden.parquet|       |\n",
      "+----------------------------+---------------------------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    " DESCRIBE TABLE EXTENDED foo.bar\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ec1b04e-79d5-4ef7-8838-fb0a40df3d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DROP TABLE foo.bar\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b55aee7-4840-4f3e-9f90-a42124fa4309",
   "metadata": {},
   "source": [
    "im datei browser anschauen, dass die Dateien nicht wirklich gelöscht wurden\n",
    "Nun mit SQL die Tabelle wieder herstellen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "019d0136-bc5f-4242-937e-175d94b19940",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Nun eine Table direkt aus parquet herstellen (parquet hat Schema eingebaut ;-) )\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE  foo.bar\n",
    "    USING PARQUET\n",
    "    LOCATION \"/home/pupil/spark-course/course/03-SQL/spark-warehouse/persistent/kunden.parquet\"\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74caf641-a5a0-492c-a31b-b5b7b8625f64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                  id|                name|\n",
      "+--------------------+--------------------+\n",
      "|ce4cf720-4a1a-11e...|             gorzala|\n",
      "|d55a2ede-4a1a-11e...|                Olli|\n",
      "|1dbdbea0-814b-46e...|        Relaxed Cray|\n",
      "|8b5d9978-c30a-4b3...|      Pedantic Ellis|\n",
      "|0232746d-2025-4dc...|  Mystifying Solomon|\n",
      "|331c4f94-82ad-443...|          Elastic Wu|\n",
      "|f783150d-95d6-425...|       Hardcore Cori|\n",
      "|89b2f281-5743-42b...|   Inspiring Solomon|\n",
      "|12c4de06-eb24-4b4...|Competent Montalcini|\n",
      "|129d91bf-35b6-44b...|        Jovial Rubin|\n",
      "|bc5967d0-2077-4d6...|            Zen Pike|\n",
      "|4b9d040f-8432-429...|   Objective Goodall|\n",
      "|14f2a015-c9e9-4bb...|   Distracted Bouman|\n",
      "|23ac28d5-0247-4e9...|   Mystifying Agnesi|\n",
      "|05a0c2f2-5701-432...|   Nostalgic Pasteur|\n",
      "|cab57827-f0bf-497...|    Awesome Poincare|\n",
      "|945cec5c-a952-4a1...|      Sleepy Hermann|\n",
      "|da324d84-5b3d-400...|  Epic Proskuriakova|\n",
      "|51249084-0897-4b6...|      Charming Gauss|\n",
      "|d4a3bf2f-66aa-485...|      Unruffled Benz|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM foo.bar\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda0b87-78e4-4910-ae5e-d1e9c02cc3e7",
   "metadata": {},
   "source": [
    "**Take Away** Spark Tables machen die Entwicklung schneller und einfacher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a32950-e0eb-402c-b782-0465657e02e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spark User Defined Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b43b6a6-0dd4-45bc-9dcf-5ee40e2bc7f0",
   "metadata": {},
   "source": [
    "Spark stellt dir zwar eine Menge an Funktionen zur Datenmanipulation zur Verfügung, aber machnchmal fehlt doch etwas.\n",
    "Aus diesem Grund gibt es User Defined Funktions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc0023f0-db16-48c3-97fa-02cad3b1a69d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------------------+-------------------+------------------------------------+\n",
      "|AntragsId                           |StartZeit          |EndZeit            |KundenId                            |\n",
      "+------------------------------------+-------------------+-------------------+------------------------------------+\n",
      "|ebd66d59-d3f9-484c-8e80-45ce16168b6c|2023-09-05 02:47:54|2023-09-05 02:53:54|1dbdbea0-814b-46ee-88a5-a92e30231a18|\n",
      "|27b66f96-9c4c-4c34-997a-ccf09933f20c|2023-09-04 13:47:39|2023-09-04 13:56:39|8b5d9978-c30a-4b32-85cb-8dd901c822bd|\n",
      "|f2c2e697-546d-4b0b-9716-771dbb92e832|2023-09-13 19:21:42|2023-09-13 19:28:42|0232746d-2025-4dc7-a9b6-94eaa90fb5d4|\n",
      "|19f45c99-84ae-444c-a7c0-831e511aa974|2023-09-14 17:50:22|2023-09-14 17:57:22|331c4f94-82ad-4435-bb75-6e9875b1aa6a|\n",
      "|7da30a98-d3db-42a4-8fb2-21b94cb58f65|2023-09-08 01:13:28|2023-09-08 01:19:28|f783150d-95d6-4257-ba00-04c34dca2cdb|\n",
      "|043ef706-9b16-4930-8113-19596c2f62ed|2023-09-05 05:25:10|2023-09-05 05:34:10|89b2f281-5743-42b9-ae02-01b3446e5f27|\n",
      "|a61d6dfa-486c-4142-a46d-a0bcb6766a01|2023-09-14 12:06:47|2023-09-14 12:10:47|12c4de06-eb24-4b4d-994d-c76f443da9fc|\n",
      "|530be6cd-7bcf-4d68-95ad-c8cbe4617349|2023-09-19 02:16:47|2023-09-19 02:19:47|129d91bf-35b6-44bc-aa5a-02a2bb0c7380|\n",
      "|0b299f13-c081-4ffe-b27b-674279520af8|2023-09-17 05:20:27|2023-09-17 05:23:27|bc5967d0-2077-4d6e-8f75-c817fc5f9f78|\n",
      "|e31ae0e3-7e86-49fb-bbaf-77345aa66edb|2023-09-05 01:30:46|2023-09-05 01:31:46|4b9d040f-8432-429c-b4e7-8ab1b1370536|\n",
      "|e4bc41ea-cbe9-4187-8356-99da175422ea|2023-09-02 20:52:19|2023-09-02 20:54:19|14f2a015-c9e9-4bbf-9f35-b883bf8d6f8d|\n",
      "|380375d3-879f-478a-b2bb-c1f8b0317478|2023-09-05 13:36:03|2023-09-05 13:38:03|23ac28d5-0247-4e9a-b90d-646609f5eee0|\n",
      "|ad015f89-8434-4be0-842e-6cf481b5785b|2023-09-08 21:53:49|2023-09-08 21:58:49|05a0c2f2-5701-432a-af28-7c39bd07bc15|\n",
      "|f67aa3ed-bd58-4cbb-8a38-bfb0ef90da36|2023-09-17 07:29:51|2023-09-17 07:32:51|null                                |\n",
      "|8562fca2-eb12-47d0-9f66-8b80c41e80b3|2023-09-06 19:14:38|2023-09-06 19:22:38|945cec5c-a952-4a12-bc49-615cf44ceb40|\n",
      "|8f1cfaff-6ac2-44cd-80d9-85051c00172f|2023-09-13 09:29:55|2023-09-13 09:38:55|da324d84-5b3d-400e-a998-ba3331ae6c76|\n",
      "|afad9aa8-b7b5-47f8-b676-18426c714ee5|2023-09-18 08:56:40|2023-09-18 08:59:40|51249084-0897-4b61-b83c-407be88108a9|\n",
      "|41400e95-3e3c-4f69-ad24-3d33142a82e5|2023-09-17 22:31:56|2023-09-17 22:35:56|d4a3bf2f-66aa-4857-ae86-ab1f9244f452|\n",
      "|d067d059-f525-4fd4-b466-7bb7ee5d11c6|2023-09-08 13:34:07|2023-09-08 13:41:07|0451f1ae-c22a-4e66-852e-4bc31dd795b8|\n",
      "|5ff6d5e8-2e42-4737-99d5-8c70a1bb8bbd|2023-09-17 22:39:04|2023-09-17 22:48:04|75df457f-6ab8-4a9f-a253-3149da16eafa|\n",
      "+------------------------------------+-------------------+-------------------+------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT * FROM antrag_erzeugt\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ec0a36-144a-496d-95fa-810355730e40",
   "metadata": {
    "tags": []
   },
   "source": [
    "Wir möchten hier zum Beispiel die Zeitauer als eigene Spalte haben, die der Kunde auf der Antragsstrecke verbracht hat. Das würde zwar auch mit SQL gehen, aber soll hier als Beispiel dienen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d07856-e51c-4c3b-9dda-70709d1b7fe6",
   "metadata": {},
   "source": [
    "**Beachte**: Für Spark sind UDFs Blackboxen und Spark wendet deswegen keinerlei Optimierungen auf deren Anwendung an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fd2baf5-e52e-4f12-906f-5060090b74a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# meine erste UDF\n",
    "def duration(first_ts, second_ts):\n",
    "    delta = second_ts - first_ts\n",
    "    return int(delta.total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "158e6140-97de-4280-a1d0-426b02e142d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "duration_udf = udf( lambda first, second: duration(first,second), IntegerType()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3d04ff-e25a-4e4a-b7c0-0e8fcec8cb6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Anwenden in Dataframe-Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1418acd0-5ea5-4478-b332-5ca1ac5a84fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------------------+-------------------+------------------------------------+--------+\n",
      "|AntragsId                           |StartZeit          |EndZeit            |KundenId                            |Duration|\n",
      "+------------------------------------+-------------------+-------------------+------------------------------------+--------+\n",
      "|ebd66d59-d3f9-484c-8e80-45ce16168b6c|2023-09-05 02:47:54|2023-09-05 02:53:54|1dbdbea0-814b-46ee-88a5-a92e30231a18|360     |\n",
      "|27b66f96-9c4c-4c34-997a-ccf09933f20c|2023-09-04 13:47:39|2023-09-04 13:56:39|8b5d9978-c30a-4b32-85cb-8dd901c822bd|540     |\n",
      "|f2c2e697-546d-4b0b-9716-771dbb92e832|2023-09-13 19:21:42|2023-09-13 19:28:42|0232746d-2025-4dc7-a9b6-94eaa90fb5d4|420     |\n",
      "|19f45c99-84ae-444c-a7c0-831e511aa974|2023-09-14 17:50:22|2023-09-14 17:57:22|331c4f94-82ad-4435-bb75-6e9875b1aa6a|420     |\n",
      "|7da30a98-d3db-42a4-8fb2-21b94cb58f65|2023-09-08 01:13:28|2023-09-08 01:19:28|f783150d-95d6-4257-ba00-04c34dca2cdb|360     |\n",
      "+------------------------------------+-------------------+-------------------+------------------------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "antrag_erzeugt_df.select(\n",
    "    \"*\",\n",
    "    duration_udf(col(\"StartZeit\"), col(\"EndZeit\")).alias(\"Duration\")\n",
    ").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2712a61f-a17f-4771-b6c1-a1fc5f2b6b1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Anwenden in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64f7283a-2b4c-4cdf-8d99-4c280ebb69c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.duration(first_ts, second_ts)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# für spark sql registrieren\n",
    "spark.udf.register(\"duration\", duration, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "229602ce-b00f-4512-a747-64f9648009d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------------------+-------------------+------------------------------------+---+\n",
      "|AntragsId                           |StartZeit          |EndZeit            |KundenId                            |Foo|\n",
      "+------------------------------------+-------------------+-------------------+------------------------------------+---+\n",
      "|ebd66d59-d3f9-484c-8e80-45ce16168b6c|2023-09-05 02:47:54|2023-09-05 02:53:54|1dbdbea0-814b-46ee-88a5-a92e30231a18|360|\n",
      "|27b66f96-9c4c-4c34-997a-ccf09933f20c|2023-09-04 13:47:39|2023-09-04 13:56:39|8b5d9978-c30a-4b32-85cb-8dd901c822bd|540|\n",
      "|f2c2e697-546d-4b0b-9716-771dbb92e832|2023-09-13 19:21:42|2023-09-13 19:28:42|0232746d-2025-4dc7-a9b6-94eaa90fb5d4|420|\n",
      "|19f45c99-84ae-444c-a7c0-831e511aa974|2023-09-14 17:50:22|2023-09-14 17:57:22|331c4f94-82ad-4435-bb75-6e9875b1aa6a|420|\n",
      "+------------------------------------+-------------------+-------------------+------------------------------------+---+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        *,\n",
    "        duration(StartZeit, Endzeit) AS Foo\n",
    "    FROM antrag_erzeugt\n",
    "\"\"\").show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3b885-8b2d-403f-ac93-6249ede33728",
   "metadata": {},
   "source": [
    "### Übung, schreibe eine UDF, die die Dauer auf einen Ampelwert abbildet\n",
    "\n",
    "* alles unter 200 Sekunden \"grün\"\n",
    "* zwischen 200 und 500 \"gelb\"\n",
    "* der rest rot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a481ed8-cdbc-4e42-b79c-8caec2b5ff92",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d509096-ab95-4219-9ba9-e243e1f42611",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](joins.dio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e6fd0b-8279-448e-927d-2743910bf3ff",
   "metadata": {},
   "source": [
    "Spark unterstützt die gängisten Joins\n",
    "\n",
    "* Inner Join\n",
    "* Left Outer Join\n",
    "* Right Outer Join\n",
    "* Full Outer Join\n",
    "\n",
    "Nur in Python und Scala verfügbar:\n",
    "\n",
    "* Cross Join\n",
    "* Semi Join\n",
    "* Anti Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dce73b-2f41-43c6-9f66-7ff46fba4a10",
   "metadata": {},
   "source": [
    "### Inner Join\n",
    "\n",
    "![](inner-join.dio.svg)\n",
    "\n",
    "\n",
    "Alle Anträge die in der Tabelle Antrag erzeugt und AB-Test drin sind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39d4c446-beff-44d6-8312-917610f61067",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------------------+-------------------+------------------------------------+------------------------------------+---+\n",
      "|AntragsId                           |StartZeit          |EndZeit            |KundenId                            |AntragsId                           |foo|\n",
      "+------------------------------------+-------------------+-------------------+------------------------------------+------------------------------------+---+\n",
      "|a61d6dfa-486c-4142-a46d-a0bcb6766a01|2023-09-14 12:06:47|2023-09-14 12:10:47|12c4de06-eb24-4b4d-994d-c76f443da9fc|a61d6dfa-486c-4142-a46d-a0bcb6766a01|240|\n",
      "|530be6cd-7bcf-4d68-95ad-c8cbe4617349|2023-09-19 02:16:47|2023-09-19 02:19:47|129d91bf-35b6-44bc-aa5a-02a2bb0c7380|530be6cd-7bcf-4d68-95ad-c8cbe4617349|180|\n",
      "|e31ae0e3-7e86-49fb-bbaf-77345aa66edb|2023-09-05 01:30:46|2023-09-05 01:31:46|4b9d040f-8432-429c-b4e7-8ab1b1370536|e31ae0e3-7e86-49fb-bbaf-77345aa66edb|60 |\n",
      "|43186a36-8130-4ffc-8311-8eebc34c65a3|2023-09-06 09:25:37|2023-09-06 09:27:37|ea23c6c0-a39f-43d1-adfb-86727a2e411a|43186a36-8130-4ffc-8311-8eebc34c65a3|120|\n",
      "|0b0d5b3c-5153-4e01-87fd-5b7f08688a90|2023-09-16 08:01:43|2023-09-16 08:05:43|null                                |0b0d5b3c-5153-4e01-87fd-5b7f08688a90|240|\n",
      "|037e0e7d-8283-4788-a22b-37832e98b3ff|2023-09-17 19:02:53|2023-09-17 19:05:53|null                                |037e0e7d-8283-4788-a22b-37832e98b3ff|180|\n",
      "|fadeccd6-dd2f-4c99-8e56-cf3efc26bbcf|2023-09-08 00:18:55|2023-09-08 00:19:55|76ffb2db-809d-49ad-a5c2-29d8eab087f5|fadeccd6-dd2f-4c99-8e56-cf3efc26bbcf|60 |\n",
      "|c25b2a5c-53db-4671-b87b-84c033bef960|2023-09-04 00:36:36|2023-09-04 00:38:36|7d4c8319-9598-460b-8c67-a33a54cbef80|c25b2a5c-53db-4671-b87b-84c033bef960|120|\n",
      "|bb5f62e8-e1b6-40b2-bbdd-331ae3e14cac|2023-09-17 21:04:47|2023-09-17 21:07:47|66cebdf0-4a8e-4c32-9b1e-972780f30ba1|bb5f62e8-e1b6-40b2-bbdd-331ae3e14cac|180|\n",
      "|2e3eb70c-42b0-4b4c-a025-83670b6811a5|2023-09-16 08:49:41|2023-09-16 08:52:41|c207db32-69e1-431e-8287-984bdbd970ab|2e3eb70c-42b0-4b4c-a025-83670b6811a5|180|\n",
      "|b0a2bf46-47ba-4cea-b3bd-003394d5ac84|2023-09-18 11:52:12|2023-09-18 11:56:12|44958936-5d6e-43e5-a36a-fc125b1dc8e1|b0a2bf46-47ba-4cea-b3bd-003394d5ac84|240|\n",
      "|d53826a0-a71f-4379-b6c3-c56ad1858f97|2023-09-02 02:29:15|2023-09-02 02:30:15|0b9cc417-1060-4b99-b7f7-0c49178034f1|d53826a0-a71f-4379-b6c3-c56ad1858f97|60 |\n",
      "|89b7c530-6f92-4716-b351-f06f3e67b405|2023-09-14 13:57:55|2023-09-14 13:58:55|9a591444-f630-4363-9ed0-f85e66875c66|89b7c530-6f92-4716-b351-f06f3e67b405|60 |\n",
      "|8d7b2f58-4ff9-4874-baa6-44b915bf335a|2023-09-10 17:32:42|2023-09-10 17:35:42|2b8bc87b-bb43-462e-b23c-f11f61fca702|8d7b2f58-4ff9-4874-baa6-44b915bf335a|180|\n",
      "|7af340f5-fed6-4bcd-b581-46d44d151c91|2023-09-18 00:16:43|2023-09-18 00:17:43|d17c5336-d1d7-4309-983a-a013b7ef5be5|7af340f5-fed6-4bcd-b581-46d44d151c91|60 |\n",
      "|c8fd9473-c70e-4c60-908e-134a893d6b29|2023-09-10 15:08:02|2023-09-10 15:09:02|a7db3be1-62f2-468e-932f-bbf7e91b2f01|c8fd9473-c70e-4c60-908e-134a893d6b29|60 |\n",
      "|85093766-82e7-431e-af42-bb68c4948ccb|2023-09-13 11:21:18|2023-09-13 11:24:18|796c2123-71aa-4201-a9f9-99ad8b52889a|85093766-82e7-431e-af42-bb68c4948ccb|180|\n",
      "|67286b67-5477-40cb-816b-162c2d0ae6bf|2023-09-13 20:34:07|2023-09-13 20:36:07|9fb98550-a919-4888-82b0-269e629a15f2|67286b67-5477-40cb-816b-162c2d0ae6bf|120|\n",
      "|fe7e693f-7a51-4ad0-b7fe-89597207d66b|2023-09-11 02:29:09|2023-09-11 02:31:09|null                                |fe7e693f-7a51-4ad0-b7fe-89597207d66b|120|\n",
      "|4015ff12-c0ba-4002-82cb-1ec0692d965f|2023-09-11 12:12:33|2023-09-11 12:15:33|ab8611cf-a0e3-48d6-9b60-58dc331658a0|4015ff12-c0ba-4002-82cb-1ec0692d965f|180|\n",
      "+------------------------------------+-------------------+-------------------+------------------------------------+------------------------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *,\n",
    "           unix_timestamp(EndZeit) - unix_timestamp(StartZeit) AS foo\n",
    "      FROM antrag_erzeugt\n",
    "INNER JOIN ab_test \n",
    "        ON antrag_erzeugt.AntragsId = ab_test.AntragsId\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1fbd141-70d4-44c4-a075-e693623105f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|119     |\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|1000    |\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT count(1)\n",
    "      FROM antrag_erzeugt\n",
    "INNER JOIN ab_test\n",
    "        ON antrag_erzeugt.AntragsId = ab_test.AntragsId\n",
    "\"\"\").show(truncate=False)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT count(1)\n",
    "      FROM antrag_erzeugt\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b67a98d6-8965-487d-8b0c-f01ceeb1c79d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# geht auch mit Dataframe API\n",
    "\n",
    "joined_df = (\n",
    "    antrag_erzeugt_df\n",
    "        .join(\n",
    "            ab_test_df,\n",
    "            antrag_erzeugt_df.AntragsId == ab_test_df.AntragsId,\n",
    "            \"inner\" # left, leftouter, right, rightouter, full etc.\n",
    "        )\n",
    ")\n",
    "joined_df.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0351937-6939-439c-af12-2f1906e6bfde",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set Operation\n",
    "\n",
    "* Union All\n",
    "* Union\n",
    "* Intersect\n",
    "* Except / Minus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7190d9-a886-4e84-b230-d2bf7f6d48b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Aufgaben\n",
    "### Identifziere Fälle in denen möglicherweise ein Event verloren geganen ist\n",
    "Wenn der Kunde zum Beispiel ein Vertragsangebot akzeptiert, dann sollten wir mit dem policieren des Vertrags reagieren. Finde Fälle in denen das nicht passiert ist.\n",
    "### Gebe Kunden mit auffallend hohen Schadenfällen aus\n",
    "Überlege Dir was auffallend hoch heißen kann.\n",
    "### Erzeuge eine Sicht pro Schadensfall mit folgenden Spalten\n",
    "\n",
    "KundenId, VertragsId, AntragsEingangTS, PoliciertTS, SchadenFall, Reguliert(ja/nein) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c707ff-9466-41f0-b7c5-edeeafbac132",
   "metadata": {},
   "source": [
    "## Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "113f1138-7673-4343-afe3-f3ef9354842c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-------+\n",
      "|     col_name|data_type|comment|\n",
      "+-------------+---------+-------+\n",
      "|   VertragsId|   string|   null|\n",
      "|   SchadensId|   string|   null|\n",
      "|Schadenshoehe|      int|   null|\n",
      "|    TimeStamp|timestamp|   null|\n",
      "+-------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  DESCRIBE schaden_gemeldet\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fb5c97a9-dd93-431f-bb61-af38948dfbdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 62:=================================================>    (182 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-----------+\n",
      "|VertragsId                          |count_cases|\n",
      "+------------------------------------+-----------+\n",
      "|2f1927ab-65bb-4731-8880-07e38822caf6|7          |\n",
      "|2c452600-d322-414b-a587-e326f105a296|7          |\n",
      "|d2775ae1-95e1-49d5-9e62-6af51ed3968c|7          |\n",
      "|43de383c-30ea-4d95-bcc6-b6f1245f9b63|6          |\n",
      "|5ea252e0-392a-4e33-8a21-a40202fc3bbc|6          |\n",
      "|7ca32486-0152-47cb-af7e-b40122041ee7|6          |\n",
      "|4bd3d9ce-94ec-4d5e-81fc-9730784c27f2|6          |\n",
      "|0ad6f771-30aa-4e16-8296-155d02b42b81|6          |\n",
      "|f49d14b8-4fcb-4931-8ef7-20e71247cf53|6          |\n",
      "|35930c72-1cf3-4860-a96c-486769019286|6          |\n",
      "|ea4e424d-b5ed-4584-9417-1ea9e17c55d1|6          |\n",
      "|41ab602b-069e-40e2-bb12-da5a976c4f06|6          |\n",
      "|33e7093c-5992-4c76-ab94-1dffe576c35b|6          |\n",
      "|3bbe040d-ccc6-44e3-8e07-b29cb90a9f34|6          |\n",
      "|ad06fb71-c2c9-44e7-9b82-b68d43bbb043|6          |\n",
      "|8a751f05-618d-49f5-b806-83ff1f278ee1|6          |\n",
      "|45bd5814-13f2-42da-9434-d86319fce478|6          |\n",
      "|f8296f04-4c2e-4aa6-a3c8-554247e2b477|6          |\n",
      "|e1008270-f0be-4e2e-81e6-46c0738a2a89|6          |\n",
      "|46b18ab1-58ce-472a-bbfe-182816a8ca2e|6          |\n",
      "+------------------------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT VertragsId, Count(1) AS count_cases \n",
    "      FROM schaden_gemeldet\n",
    "  GROUP BY VertragsId\n",
    "  ORDER BY count_cases DESC\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce27a57-72e5-47d6-8070-83f5b032bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    WITH total_stat as SELECT * FROM \n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b4d4cb-c9c2-49c6-925d-6b0e69de0836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@deathbeds/ipydrawio": {
   "xml": "<mxfile host=\"pupil-a.bin-ich-tot.de\" modified=\"2023-09-04T09:35:05.741Z\" agent=\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\" version=\"21.1.6\" etag=\"V5d1q9Xg-VIdT2s2M7ay\" type=\"embed\">\n  <diagram id=\"zsaFwEb8lurTMNKA9gXb\" name=\"Page-1\">\n    <mxGraphModel dx=\"1036\" dy=\"570\" grid=\"1\" gridSize=\"10\" guides=\"1\" tooltips=\"1\" connect=\"1\" arrows=\"1\" fold=\"1\" page=\"1\" pageScale=\"1\" pageWidth=\"827\" pageHeight=\"1169\" math=\"0\" shadow=\"0\">\n      <root>\n        <mxCell id=\"0\" />\n        <mxCell id=\"1\" parent=\"0\" />\n        <mxCell id=\"2\" value=\"\" style=\"rounded=0;\" vertex=\"1\" parent=\"1\">\n          <mxGeometry x=\"120\" y=\"120\" width=\"120\" height=\"60\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"3\" value=\"\" style=\"rounded=0;\" vertex=\"1\" parent=\"1\">\n          <mxGeometry x=\"294\" y=\"130\" width=\"120\" height=\"60\" as=\"geometry\" />\n        </mxCell>\n      </root>\n    </mxGraphModel>\n  </diagram>\n</mxfile>\n"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
