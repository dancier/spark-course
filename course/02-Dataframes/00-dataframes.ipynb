{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976b4130-4eba-4c43-bc37-cb14652f9332",
   "metadata": {},
   "source": [
    "# Dataframe - Higher level API auf RDDs\n",
    "\n",
    "Wir haben uns vorhin RDDs angeschaut. Diese bieten uns schon eine Reihe nützlicher Feature an. Viele Optimierungen müssen wir aber von Hand vornehmen.\n",
    "\n",
    "Wir werden sehen, was dass wir mit Dataframe einfach nur einfacher und eleganter entwickeln können, sondern das der Code viel schneller ist, als nicht optimierter RDD Code.\n",
    "\n",
    "Wir werden ganz praktisch:\n",
    "\n",
    "* Sehen wie wir Dataframes erzeugen können\n",
    "* Schemata auf Daten anwenden\n",
    "* Daten analysieren und bereinigen\n",
    "* Transformationen anwenden\n",
    "\n",
    "[API-Doc](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/dataframe.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cae72d-1439-413c-80ce-d55cb27a4aec",
   "metadata": {},
   "source": [
    "## Spark Optimierungen auf Dataframes\n",
    "\n",
    "Es gibt zwei wesentliche Ansätze an denen Spark Optimierungen vornimmt\n",
    "\n",
    "![](spark-optimierungen.dio.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1038a2-70f6-45fa-9edc-9ef20f851e57",
   "metadata": {},
   "source": [
    "## [Catalyst Optimierer](https://www.databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html)\n",
    "\n",
    "Der Catalyst optimiert den Ausführungsplan. Wer sich mal bei PostgreSQL mit [_explain_](https://www.postgresql.org/docs/current/sql-explain.html) den Plan für sein Statement angeschaut hat, der hat schon eine Idee was der Catalyst macht.\n",
    "\n",
    "![](optimisation-phases.svg)\n",
    "### Analyse-Phase\n",
    "\n",
    "1. Syntax Check\n",
    "1. Erzeuge: Unresolved logical Plan (unresolved, weil weder geprüft wird ob referenziert Spalten existieren, noch ob sie den richtigen Typ haben...)\n",
    "1. Nun wird mit Hilfe des Cataloges (Verzeichniss aller Spalten/Tabellen/Datentypen) der logische Plan erzeugt. Jetzt ist geklärt ob die Spalten existieren und passen...\n",
    "\n",
    "### Logische Optimierung\n",
    "\n",
    "  * [Predicate Pushdown](https://medium.com/microsoftazure/data-at-scale-learn-how-predicate-pushdown-will-save-you-money-7063b80878d7)\n",
    "  * [Constant folding](https://en.wikipedia.org/wiki/Constant_folding)\n",
    "  * ...\n",
    "\n",
    "Dies führt zu optimierten logischen Plan.\n",
    "\n",
    "### Physical Planning\n",
    "\n",
    "Für den optimierten logsichen Plan werden ein Reihe von physischen Plänen berechnet und mit einem Kostenmodell bewertet. Der Günstige wird dann genommen.\n",
    "\n",
    "### Code Generation\n",
    "\n",
    "Am Ende sind es wieder RDDs die in Java Bytecode überführt werden.\n",
    "\n",
    "### Beachte\n",
    "\n",
    "* All diese Optimierungen bekommst Du nicht, wenn Du direkt RDD Code schreibst. Diese müsstest Du selbst finden und ausprogrammieren.\n",
    "* Dies führt auch dazu, dass Dataframe-Code in der Regel nahezu so schnell ist wie handoptimierter RDD-Code. (überlege selber ob Du diese Optimierungen überhaupt selber schreiben kannst oder willst)\n",
    "* Das führt ebenfalls dazu, dass Python/R/SQL/Scala-Dataframe-Code gleichschnell sind, weil sie alle in RDD Code überführt werden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecd6f932-8acc-4349-bb24-6a19687713c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/10 08:53:07 WARN Utils: Your hostname, keen-northcutt resolves to a loopback address: 127.0.1.1; using 116.203.107.225 instead (on interface eth0)\n",
      "23/09/10 08:53:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/10 08:53:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://keen-northcutt.bin-ich-tot.de:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>catalyst</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9aa76e7190>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder\n",
    "        .appName(\"catalyst\")\n",
    "        .master(\"local[4]\")  \n",
    "        .config(\"spark.dynamicAllocation.enabled\",False)\n",
    "        .config(\"spark.sql.adaptive.enabled\",False)\n",
    "        .getOrCreate()\n",
    ")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4792dce-b826-47e8-ac79-bb903b6ac325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|PULocationID|count|\n",
      "+------------+-----+\n",
      "|         148|38049|\n",
      "|         243|  514|\n",
      "|          31|   22|\n",
      "|         137|43171|\n",
      "|         251|    6|\n",
      "|          85|   95|\n",
      "|          65| 3042|\n",
      "|         255| 1969|\n",
      "|          53|   41|\n",
      "|         133|   92|\n",
      "|          78|  113|\n",
      "|         155|  127|\n",
      "|         108|   78|\n",
      "|         211|26838|\n",
      "|         193| 3383|\n",
      "|          34|  113|\n",
      "|         126|   67|\n",
      "|         101|   50|\n",
      "|         115|    5|\n",
      "|          81|   73|\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import schemata\n",
    "taxi_rides_df = spark.read.csv(\"YellowTaxis_202210.csv.gz\", header = True, schema=schemata.yellow_taxi_schema)\n",
    "\n",
    "taxi_rides_by_location = taxi_rides_df.groupby(\"PULocationID\").count()\n",
    "\n",
    "filtered_taxi_rides_by_location = taxi_rides_by_location.where(\"PULocationID == 81\")\n",
    "\n",
    "taxi_rides_by_location.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de868f1-f68c-4729-9343-37aebe239a51",
   "metadata": {},
   "source": [
    "![](different-concrete-plans.dio.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d7d784-2fff-461a-a6c9-52538289e7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
