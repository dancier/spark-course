{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43614523-3598-4a63-a37f-c133c5813634",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e92a1c9-82de-4f82-af19-ef5759c2905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "we are now switching to a higher level api:\n",
    "\n",
    "Dataframes\n",
    "\n",
    "they are build upon RDD but will make our life much simpleer\n",
    "\n",
    "They will inherit some of the greate attributes of RDD:\n",
    "\n",
    " * in memory\n",
    " * partitioned\n",
    " * resilient\n",
    " * read only\n",
    "\n",
    "Treats the Data similar like relational databases:\n",
    "\n",
    "Set of Rows where each row has columns of certain types\n",
    "\n",
    "\n",
    "Dataframes\n",
    "\n",
    "will alow spark to apply optimazations that plain rdd will now allow\n",
    "\n",
    "this leads to less development effort\n",
    "\n",
    "current an future developtment of spark is mostly on dataframe apis\n",
    "\n",
    "when you have no proper reason, default to dataframes\n",
    "\n",
    "\n",
    "Optimizations on build time\n",
    "by catalyst optimizer for query optimization\n",
    "\n",
    "and with tungsten on runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e381b194-1084-4740-a4fd-2a661bf50190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/21 07:25:43 WARN Utils: Your hostname, pupil-a resolves to a loopback address: 127.0.1.1; using 167.235.141.210 instead (on interface eth0)\n",
      "23/08/21 07:25:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/21 07:25:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/08/21 07:25:46 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/08/21 07:25:46 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"dataframes\").master(\"local[4]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78788983-567e-427d-8ecf-94d62ad857bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://pupil-a.bin-ich-tot.de:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>dataframes</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f7c44987a00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c654120-25b9-42e9-8ab0-df0f1114cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "422e9326-b5f3-4163-a356-07da84b0078f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcac6da8-e32d-4386-95ea-efc5fca25ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_df = spark.read.csv(\"deaths.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8907f8c5-af21-4bb4-8222-ac646a7dedd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[country: string, placename: string, frequency: string, start_date: string, end_date: string, year: string, month: string, week: string, deaths: string, expected_deaths: string, excess_deaths: string, baseline: string]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deaths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "247ae521-3de8-42f8-b792-1d1ab413660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_by_country = deaths_df.groupby(\"country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "340de82a-1622-4a4d-b212-e7dce1edbda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(country='Russia', count=71),\n",
       " Row(country='Sweden', count=305),\n",
       " Row(country='Turkey', count=153),\n",
       " Row(country='Germany', count=252),\n",
       " Row(country='France', count=551),\n",
       " Row(country='Belgium', count=300),\n",
       " Row(country='Ecuador', count=40),\n",
       " Row(country='Finland', count=203),\n",
       " Row(country='Peru', count=60),\n",
       " Row(country='India', count=19)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deaths_by_country.count().take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a25767fc-a5e1-40af-aec5-d9deee6e8fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, country: string, placename: string, frequency: string, start_date: string, end_date: string, year: string, month: string, week: string, deaths: string, expected_deaths: string, excess_deaths: string, baseline: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deaths_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9773532f-866d-4c89-8390-dbf0de3c0ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(deaths_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "358ee1b0-6599-4604-b9a6-530e5bdf9d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(country='Austria', placename=None, frequency='weekly', start_date='2020-01-06', end_date='2020-01-12', year='2020', month='1', week='2', deaths='1702', expected_deaths='1806', excess_deaths='-104', baseline='2015-2019 historical data'),\n",
       " Row(country='Austria', placename=None, frequency='weekly', start_date='2020-01-13', end_date='2020-01-19', year='2020', month='1', week='3', deaths='1797', expected_deaths='1819', excess_deaths='-22', baseline='2015-2019 historical data')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deaths_df.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fd95edd-3ad0-4698-b8e8-ded9bcdf5a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+----------+----------+----+-----+----+------+---------------+-------------+--------------------+\n",
      "|    _c0|      _c1|      _c2|       _c3|       _c4| _c5|  _c6| _c7|   _c8|            _c9|         _c10|                _c11|\n",
      "+-------+---------+---------+----------+----------+----+-----+----+------+---------------+-------------+--------------------+\n",
      "|country|placename|frequency|start_date|  end_date|year|month|week|deaths|expected_deaths|excess_deaths|            baseline|\n",
      "|Austria|     null|   weekly|2020-01-06|2020-01-12|2020|    1|   2|  1702|           1806|         -104|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-01-13|2020-01-19|2020|    1|   3|  1797|           1819|          -22|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-01-20|2020-01-26|2020|    1|   4|  1779|           1831|          -52|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-01-27|2020-02-02|2020|    2|   5|  1947|           1837|          110|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-02-03|2020-02-09|2020|    2|   6|  1681|           1837|         -156|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-02-10|2020-02-16|2020|    2|   7|  1721|           1829|         -108|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-02-17|2020-02-23|2020|    2|   8|  1718|           1812|          -94|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-02-24|2020-03-01|2020|    3|   9|  1768|           1786|          -18|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-03-02|2020-03-08|2020|    3|  10|  1744|           1753|           -9|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-03-09|2020-03-15|2020|    3|  11|  1718|           1717|            1|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-03-16|2020-03-22|2020|    3|  12|  1836|           1678|          158|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-03-23|2020-03-29|2020|    3|  13|  1765|           1640|          125|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-03-30|2020-04-05|2020|    4|  14|  1828|           1603|          225|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-04-06|2020-04-12|2020|    4|  15|  1793|           1570|          223|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-04-13|2020-04-19|2020|    4|  16|  1704|           1539|          165|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-04-20|2020-04-26|2020|    4|  17|  1588|           1512|           76|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-04-27|2020-05-03|2020|    5|  18|  1480|           1487|           -7|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-05-04|2020-05-10|2020|    5|  19|  1520|           1467|           53|2015-2019 histori...|\n",
      "|Austria|     null|   weekly|2020-05-11|2020-05-17|2020|    5|  20|  1489|           1450|           39|2015-2019 histori...|\n",
      "+-------+---------+---------+----------+----------+----+-----+----+------+---------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deaths_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56549498-69ec-41ca-8012-81b8d865ef50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
